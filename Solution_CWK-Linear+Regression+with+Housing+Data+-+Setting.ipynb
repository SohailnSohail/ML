{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:\n",
    "##### Having imported the data, write code to study the following data characteristics:\n",
    "        a) number of rows and columns for the independent variables\n",
    "        b) labels of the columns for the independent variables and their meaning\n",
    "        c) target variable values and their meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution to Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for independent variables: 20640\n",
      "Number of columns for independent variables: 8\n",
      "Labels and meanings of columns for independent variables:\n",
      "MedInc:         - HouseAge      median house age in block group\n",
      "HouseAge:         - AveRooms      average number of rooms per household\n",
      "AveRooms:         - AveBedrms     average number of bedrooms per household\n",
      "AveBedrms:         - Population    block group population\n",
      "Population:         - AveOccup      average number of household members\n",
      "AveOccup:         - Latitude      block group latitude\n",
      "Latitude:         - Longitude     block group longitude\n",
      "\n",
      "Target variable values:\n",
      "[4.526 3.585 3.521 3.413 3.422]\n",
      "\n",
      "Target variable name: MedHouseVal\n",
      "Meaning of target variable: the median house value for California districts,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Fetch the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Task 1: Data Characteristics\n",
    "# a) Number of rows and columns for the independent variables\n",
    "num_rows, num_cols = housing.data.shape\n",
    "print(\"Number of rows for independent variables:\", num_rows)\n",
    "print(\"Number of columns for independent variables:\", num_cols)\n",
    "\n",
    "# b) Labels of the columns for the independent variables and their meaning\n",
    "column_labels = housing.feature_names\n",
    "column_meaning = housing.DESCR.split(\"Attribute Information:\")[-1].split(\":Missing Attribute Values:\")[0].strip().split(\"\\n\")[1:]\n",
    "columns_info = dict(zip(column_labels, column_meaning))\n",
    "print(\"Labels and meanings of columns for independent variables:\")\n",
    "for label, meaning in columns_info.items():\n",
    "    print(f\"{label}: {meaning}\")\n",
    "\n",
    "# c) Target variable values and their meaning\n",
    "target_values = housing.target\n",
    "target_name = housing.target_names[0]\n",
    "target_meaning = housing.DESCR.split(\"The target variable is \")[-1].split(\"\\n\")[0]\n",
    "print(\"\\nTarget variable values:\")\n",
    "print(target_values[:5])  # Display first 5 values\n",
    "print(\"\\nTarget variable name:\", target_name)\n",
    "print(\"Meaning of target variable:\", target_meaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2:\n",
    "##### Write the code to train prediction models with a data split ratio 80/20 between training and test data. Your code should also consider reshuffling of the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution to Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5078085968729842\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = r'D:\\CLIENT Asignment\\california_housing_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# Splitting the data into training and test sets with shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Training the model (Example: Linear Regression)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2:\n",
    "##### Having performed scaling for all values, you should develop the following regression models:\n",
    "        a) a Linear Regression model by displaying its intercept, trained coefficients, RMSE score as fitness metric.\n",
    "        b) a Stochastic Gradient Descent with Warm Restarts model, which is a variant of the stochastic gradient descent (SGD) optimisation algorithm commonly used in machine learning for training linear models, including linear regression models. You should display its intercept, trained coefficients, RMSE score as fitness metric. \n",
    "        b.1) For the model above, you should use 10 iterations as maximum and set both tol and eta, which are essential hyperparameters that need to be tuned carefully to achieve the desired balance between convergence speed and solution quality, as you think appropriate.\n",
    "        c) Prepare the data and develop a model of a higher degree polynomial, for instance, degree = 2. You should display its intercept, trained coefficients, RMSE score as fitness metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution to Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Linear Regression model by displaying its intercept, trained coefficients, RMSE score as fitness metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 2.0682855935077566\n",
      "Coefficients: [ 0.82502434  0.1184549  -0.25900377  0.3030255  -0.00631966 -0.03895182\n",
      " -0.91015401 -0.88707079]\n",
      "RMSE Score: 0.7431262670963512\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = r'D:\\CLIENT Asignment\\california_housing_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# Splitting the data into training and test sets with shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Training the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Getting intercept and coefficients\n",
    "intercept = model.intercept_\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Displaying results\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"RMSE Score:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  a Stochastic Gradient Descent with Warm Restarts model, which is a variant of the stochastic gradient descent (SGD) optimisation algorithm commonly used in machine learning for training linear models, including linear regression models. You should display its intercept, trained coefficients, RMSE score as fitness metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = r'D:\\CLIENT Asignment\\california_housing_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# Splitting the data into training and test sets with shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Training the Stochastic Gradient Descent with Warm Restarts model\n",
    "model = SGDRegressor(max_iter=1000, warm_start=True)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Getting intercept and coefficients\n",
    "intercept = model.intercept_\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Displaying results\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"RMSE Score:\", rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  For the model above, you should use 10 iterations as maximum and set both tol and eta, which are essential hyperparameters that need to be tuned carefully to achieve the desired balance between convergence speed and solution quality, as you think appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-8.83165267]\n",
      "Coefficients: [-1.94931212e+01  5.63726955e+00  3.33676506e+01 -1.34036831e+01\n",
      "  1.59871111e+01 -1.09750788e+03 -1.55752235e+01 -9.23622965e-01]\n",
      "RMSE Score: 1054.3222563721017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the CSV file\n",
    "file_path = r'D:\\CLIENT Asignment\\california_housing_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# Splitting the data into training and test sets with shuffling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Training the Stochastic Gradient Descent with Warm Restarts model\n",
    "model = SGDRegressor(max_iter=10, warm_start=True, tol=1e-4, eta0=0.01)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Getting intercept and coefficients\n",
    "intercept = model.intercept_\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Displaying results\n",
    "print(\"Intercept:\", intercept)\n",
    "print(\"Coefficients:\", coefficients)\n",
    "print(\"RMSE Score:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
